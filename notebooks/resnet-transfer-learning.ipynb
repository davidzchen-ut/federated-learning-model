{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_pkl = open('./files/COCO/personimages.pkl', 'rb')\n",
    "person_matrices = pickle.load(person_pkl)\n",
    "\n",
    "no_person_pkl = open('./files/COCO/nopersonimages.pkl', 'rb')\n",
    "no_person_matrices = pickle.load(no_person_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_test_pkl = open('./files/COCO/personimagesTest.pkl', 'rb')\n",
    "person_test_matrices = pickle.load(person_test_pkl)\n",
    "\n",
    "no_person_test_pkl = open('./files/COCO/nopersonimagesTest.pkl', 'rb')\n",
    "no_person_test_matrices = pickle.load(no_person_test_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(Dataset):\n",
    "    \"\"\" Our custom Coco Dataset \"\"\"\n",
    "    \n",
    "    def __init__(self, matrix, person, transform=None):\n",
    "        self.matrix = matrix\n",
    "        self.transform = transform\n",
    "        self.person = person\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.matrix)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = self.matrix[idx]\n",
    "        person = self.person[idx]\n",
    "\n",
    "        try:\n",
    "            if self.transform:\n",
    "                sample = (self.transform(Image.fromarray(sample[0])), person)\n",
    "            else:\n",
    "                sample = (Image.fromarray(sample[0]), person)\n",
    "        except:\n",
    "            sample = None\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(person_matrices)\n",
    "dataset = CocoDataset(\n",
    "    person_matrices + no_person_matrices,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    person=np.concatenate((np.ones(num_samples, dtype=np.int_), np.zeros(num_samples, dtype=np.int_)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = len(person_test_matrices)\n",
    "test_dataset = CocoDataset(\n",
    "    person_test_matrices + no_person_test_matrices,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    person=np.concatenate((np.ones(num_test_samples, dtype=np.int_), np.zeros(num_test_samples, dtype=np.int_)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {'train': num_samples*2, 'val': num_test_samples*2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_v(batch):\n",
    "    print(batch)\n",
    "    batch = list(filter(lambda x : x is not None, batch))\n",
    "    return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': train_loader, 'val': test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet.fc = nn.Linear(2048, 2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.8490 Acc: 0.5500\n",
      "val Loss: 0.5073 Acc: 0.6875\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.0097 Acc: 0.5750\n",
      "val Loss: 0.6041 Acc: 0.6875\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.8588 Acc: 0.6375\n",
      "val Loss: 0.5727 Acc: 0.7250\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.8189 Acc: 0.6667\n",
      "val Loss: 0.5114 Acc: 0.7625\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.7190 Acc: 0.6792\n",
      "val Loss: 0.5492 Acc: 0.7750\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.9461 Acc: 0.6708\n",
      "val Loss: 0.5754 Acc: 0.7375\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.0097 Acc: 0.6417\n",
      "val Loss: 1.7395 Acc: 0.6125\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.8003 Acc: 0.6833\n",
      "val Loss: 0.5324 Acc: 0.7625\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.5800 Acc: 0.7083\n",
      "val Loss: 0.6160 Acc: 0.7125\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.5594 Acc: 0.7458\n",
      "val Loss: 0.6140 Acc: 0.7375\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.5697 Acc: 0.7292\n",
      "val Loss: 0.5755 Acc: 0.7625\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.5365 Acc: 0.7417\n",
      "val Loss: 0.5674 Acc: 0.7375\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.5454 Acc: 0.7250\n",
      "val Loss: 0.5538 Acc: 0.7375\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.5969 Acc: 0.7042\n",
      "val Loss: 0.5552 Acc: 0.7500\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.5862 Acc: 0.7167\n",
      "val Loss: 0.5452 Acc: 0.7875\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.5883 Acc: 0.6917\n",
      "val Loss: 0.5709 Acc: 0.7875\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.4833 Acc: 0.7667\n",
      "val Loss: 0.5197 Acc: 0.8000\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.4837 Acc: 0.7417\n",
      "val Loss: 0.5139 Acc: 0.7375\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.5748 Acc: 0.7083\n",
      "val Loss: 0.5806 Acc: 0.7375\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.5310 Acc: 0.7583\n",
      "val Loss: 0.5476 Acc: 0.7750\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.5402 Acc: 0.7000\n",
      "val Loss: 0.5679 Acc: 0.7375\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.5338 Acc: 0.7042\n",
      "val Loss: 0.5812 Acc: 0.7250\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.5390 Acc: 0.7208\n",
      "val Loss: 0.5297 Acc: 0.7625\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.4706 Acc: 0.7375\n",
      "val Loss: 0.5461 Acc: 0.7500\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.5676 Acc: 0.7292\n",
      "val Loss: 0.5074 Acc: 0.7750\n",
      "\n",
      "Training complete in 11m 51s\n",
      "Best val Acc: 0.800000\n"
     ]
    }
   ],
   "source": [
    "resnet = train_model(resnet, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
