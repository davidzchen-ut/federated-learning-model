{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools from git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI in c:\\users\\ashwi\\anaconda3\\lib\\site-packages (2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 20.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/philferriere/cocoapi.git#egg=pycocotools^&subdirectory=PythonAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pickle\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the annotations for stuff categories (backgrounds)\n",
    "# This cell depends on local file path to annotations\n",
    "dataDir='train2017'\n",
    "dataType='train2017'\n",
    "annFile='{}/annotations/stuff_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=71.45s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdoor_stuff = set([\"water\", \"ground\", \"solid\", \"sky\", \"plant\", \"structural\", \"building\"])\n",
    "indoor_stuff = set([\"food-stuff\", \"textile\", \"furniture-stuff\", \"window\", \"floor\", \"ceiling\", \"wall\", \"raw-material\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Set for Each Supercategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = outdoor_stuff.union(indoor_stuff)\n",
    "supercategory_ids = coco.getCatIds(supNms=stuff)\n",
    "\n",
    "list_of_supercategory_img_ids = list()\n",
    "for supercategory_id in supercategory_ids:\n",
    "    list_of_supercategory_img_ids.append(set(coco.getImgIds(catIds = supercategory_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Person / No Person Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=23.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load the annotations for thing categories (objects in image)\n",
    "# This cell depends on local file path to annotations\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Img Ids for images containing people and images with no people\n",
    "person_id = coco.getCatIds(catNms=['person'])\n",
    "only_people_imgs = set(coco.getImgIds(catIds = person_id))\n",
    "all_img_ids = set(coco.getImgIds())\n",
    "no_people_imgs = list(all_img_ids - only_people_imgs)\n",
    "only_people_imgs = list(only_people_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the people and no people img ids for EACH supercategory\n",
    "list_supercategory_people_img_ids = list()\n",
    "list_supercategory_no_people_img_ids = list()\n",
    "for supercategory_img_ids in list_of_supercategory_img_ids:\n",
    "    supercategory_people_imgs = list(set(supercategory_img_ids) & (set(only_people_imgs)))\n",
    "    list_supercategory_people_img_ids.append(supercategory_img_ids)\n",
    "    supercategory_no_people_imgs = list(set(supercategory_img_ids) & (set(no_people_imgs)))\n",
    "    list_supercategory_no_people_img_ids.append(supercategory_no_people_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Img Id Sets to Images in .pkl format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = list()\n",
    "supercategory_to_count = dict()\n",
    "\n",
    "# Currently hardcoded dataset to only package 1000 no people images\n",
    "for img_id in no_people_imgs[0:1000]:\n",
    "    annotation_ids = coco.getAnnIds(img_id)\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "    already_seen_categories = set()\n",
    "    already_seen_categories.add(\"no-person\")\n",
    "    for i in range(len(annotations)):\n",
    "        entity_id = annotations[i][\"category_id\"]\n",
    "        entity = coco.loadCats(entity_id)[0][\"supercategory\"]\n",
    "        if(entity == \"other\"):\n",
    "            continue\n",
    "        if(entity not in already_seen_categories):\n",
    "            already_seen_categories.add(entity)\n",
    "    \n",
    "    img = coco.loadImgs(img_id)[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    all_imgs.append((I,already_seen_categories))\n",
    "    \n",
    "# Currently hardcoded dataset to only package 1000 people images\n",
    "for img_id in only_people_imgs[0:1000]:\n",
    "    annotation_ids = coco.getAnnIds(img_id)\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "    already_seen_categories = set()\n",
    "    already_seen_categories.add(\"person\")\n",
    "    for i in range(len(annotations)):\n",
    "        entity_id = annotations[i][\"category_id\"]\n",
    "        entity = coco.loadCats(entity_id)[0][\"supercategory\"]\n",
    "        if(entity == \"other\"):\n",
    "            continue\n",
    "        if(entity not in already_seen_categories):\n",
    "            already_seen_categories.add(entity)\n",
    "    \n",
    "    img = coco.loadImgs(img_id)[0]\n",
    "    I = io.imread(img['coco_url'])\n",
    "    all_imgs.append((I,already_seen_categories))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert in memory images to .pkl to be used by demo\n",
    "with open('federated-learning-data.pkl', 'wb') as f:\n",
    "    pickle.dump(all_imgs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
